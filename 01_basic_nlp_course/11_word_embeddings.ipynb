{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0c2eab",
   "metadata": {},
   "source": [
    "# Basic NLP Course\n",
    "\n",
    "## Introduction to Word Embeddings\n",
    "\n",
    "Word embeddings are dense vector representations of words that capture their meanings, semantic relationships, and syntactic roles. Unlike traditional methods like Bag of Words or TF-IDF, word embeddings encode words in a continuous vector space, enabling models to understand the context and relationships between words.\n",
    "\n",
    "### Concepts of Word Embeddings\n",
    "\n",
    "- **Dense Representation**: Words are represented as dense vectors in a lower-dimensional space, unlike sparse representations in traditional methods.\n",
    "- **Semantic Similarity**: Words with similar meanings are located closer together in the vector space.\n",
    "- **Contextual Understanding**: Embeddings capture the context in which words appear, improving the model's ability to understand language.\n",
    "\n",
    "### Popular Word Embedding Models\n",
    "\n",
    "1. **Word2Vec**:\n",
    "    - Developed by Google.\n",
    "    - Two architectures: Continuous Bag of Words (CBOW) and Skip-Gram.\n",
    "    - CBOW predicts a word given its context, while Skip-Gram predicts the context given a word.\n",
    "\n",
    "2. **GloVe (Global Vectors for Word Representation)**:\n",
    "    - Developed by Stanford.\n",
    "    - Combines global word co-occurrence statistics with local context to generate embeddings.\n",
    "\n",
    "3. **FastText**:\n",
    "    - Developed by Facebook.\n",
    "    - Extends Word2Vec by representing words as subword units, enabling it to handle rare and out-of-vocabulary words.\n",
    "\n",
    "4. **BERT (Bidirectional Encoder Representations from Transformers)**:\n",
    "    - Developed by Google.\n",
    "    - Contextual embeddings that consider the entire sentence, providing different vectors for the same word in different contexts.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider the words \"king\", \"queen\", \"man\", and \"woman\". Word embeddings can capture relationships such as:\n",
    "- **king - man + woman ≈ queen**\n",
    "\n",
    "This demonstrates how embeddings encode semantic relationships.\n",
    "\n",
    "### Pros and Cons\n",
    "\n",
    "| Feature       | Word Embeddings                                |\n",
    "|---------------|------------------------------------------------|\n",
    "| **Pros**      | Captures semantic and syntactic relationships. |\n",
    "|               | Dense representation reduces dimensionality.   |\n",
    "|               | Improves performance on NLP tasks.             |\n",
    "| **Cons**      | Requires large datasets for training.          |\n",
    "|               | Pre-trained embeddings may not fit specific domains. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fe6ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd12e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5545a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load large model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455126dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure_mode</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Internal leakage</td>\n",
       "      <td>Compressor CP-001 is experiencing internal lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abnormal instrument reading</td>\n",
       "      <td>Compressor CP-101 is showing abnormal pressure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abnormal instrument reading</td>\n",
       "      <td>Compressor C-101 is giving an abnormal high pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abnormal instrument reading</td>\n",
       "      <td>Compressor C-101-A is giving abnormal instrume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abnormal instrument reading</td>\n",
       "      <td>Compressor CP-101 is giving an abnormal instru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  failure_mode  \\\n",
       "0             Internal leakage   \n",
       "1  Abnormal instrument reading   \n",
       "2  Abnormal instrument reading   \n",
       "3  Abnormal instrument reading   \n",
       "4  Abnormal instrument reading   \n",
       "\n",
       "                                         description  \n",
       "0  Compressor CP-001 is experiencing internal lea...  \n",
       "1  Compressor CP-101 is showing abnormal pressure...  \n",
       "2  Compressor C-101 is giving an abnormal high pr...  \n",
       "3  Compressor C-101-A is giving abnormal instrume...  \n",
       "4  Compressor CP-101 is giving an abnormal instru...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load work order samples\n",
    "data = pd.read_csv('../data/work_orders_sample.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0b4ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressor leak on process line, suspected worn piston rings.\n"
     ]
    }
   ],
   "source": [
    "sample_description = data.sample(1)['description'].values[0]\n",
    "print(sample_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6144e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressor   True 7.24 False False PROPN \n",
      "leak         True 6.62 False False NOUN  \n",
      "on           True 5.22 False True ADP   \n",
      "process      True 6.46 False False NOUN  \n",
      "line         True 5.82 False False NOUN  \n",
      ",            True 5.09 False False PUNCT \n",
      "suspected    True 6.48 False False VERB  \n",
      "worn         True 6.53 False False VERB  \n",
      "piston       True 7.63 False False NOUN  \n",
      "rings        True 6.58 False False NOUN  \n",
      ".            True 4.93 False False PUNCT \n"
     ]
    }
   ],
   "source": [
    "for token in nlp(sample_description):\n",
    "    print(f'{token.text:{12}} {token.has_vector} {token.vector_norm:.2f} {token.is_oov} {token.is_stop} {token.pos_:{6}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c4d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# investigate vector shape\n",
    "print(f\"Vector shape: {nlp.vocab['cat'].vector.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47396fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressor   <--> machine      0.3332\n",
      "leak         <--> machine      0.2174\n",
      "on           <--> machine      0.2343\n",
      "process      <--> machine      0.4120\n",
      "line         <--> machine      0.3479\n",
      ",            <--> machine      0.1672\n",
      "suspected    <--> machine      0.1293\n",
      "worn         <--> machine      0.1985\n",
      "piston       <--> machine      0.3027\n",
      "rings        <--> machine      0.1988\n",
      ".            <--> machine      0.2211\n"
     ]
    }
   ],
   "source": [
    "# establish similarity between words\n",
    "base_word = nlp('machine')\n",
    "\n",
    "for token in nlp(sample_description):\n",
    "    print(f'{token.text:{12}} <--> {base_word.text:{12}} {token.similarity(base_word):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0688d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'compressor' and the combination of 'machine', 'rotating', and 'gas': 0.5097\n"
     ]
    }
   ],
   "source": [
    "compressor = nlp('compressor')\n",
    "machine = nlp('machine')\n",
    "rotating = nlp('rotating')\n",
    "gas = nlp('gas')\n",
    "\n",
    "new_compressor = machine.vector + rotating.vector + gas.vector\n",
    "\n",
    "cosine_sim = cosine_similarity([compressor.vector], [new_compressor])\n",
    "print(f\"Cosine similarity between 'compressor' and the combination of 'machine', 'rotating', and 'gas': {cosine_sim[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
